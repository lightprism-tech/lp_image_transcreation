# Environment Configuration Example
# Copy this file to .env and customize for your environment

# Application Environment (development, production, testing)
PERCEPTION_ENV=development
DEBUG=true

# Paths (optional - defaults to project structure)
# Uncomment and modify if you want custom paths
# MODELS_DIR=/path/to/models
# DATA_DIR=/path/to/data
# CACHE_DIR=/path/to/cache
# OUTPUT_DIR=/path/to/outputs

# Model Configuration
BLIP_MODEL=Salesforce/blip-image-captioning-base
CLIP_MODEL=openai/clip-vit-large-patch14

# Detection Thresholds
OBJECT_THRESHOLD=0.5
TEXT_THRESHOLD=0.6
CLASSIFICATION_THRESHOLD=0.7

# Processing Settings
BATCH_SIZE=1
OCR_GPU=false

# Output Settings
SAVE_DEBUG=true
LOG_LEVEL=INFO

# HuggingFace Cache (optional)
# HF_HOME=/path/to/huggingface/cache
